{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TiM6gYg0nhkY"
      },
      "source": [
        "<font color=\"#de3023\"><h1><b>REMINDER MAKE A COPY OF THIS NOTEBOOK, DO NOT EDIT</b></h1></font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sq-JhCcLpBwS"
      },
      "source": [
        "#Conscientious Cars 2: Convolutional Neural Nets\n",
        "\n",
        "Welcome back to CC: ConscientiousCars! Today, we'll be improving on our system for distinguishing dogs from roads, so we can keep these cute puppers safe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhNVum16scIW"
      },
      "source": [
        "#@title Run this to load some packages and data! { display-mode: \"form\" }\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import model_selection\n",
        "from sklearn.metrics import accuracy_score\n",
        "from collections import Counter\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D\n",
        "from keras.layers import Activation, MaxPooling2D, Dropout, Flatten, Reshape\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def categorical_to_numpy(labels_in):\n",
        "  labels = []\n",
        "  for label in labels_in:\n",
        "    if label == 'dog':\n",
        "      labels.append(np.array([1, 0]))\n",
        "    else:\n",
        "      labels.append(np.array([0, 1]))\n",
        "  return np.array(labels)\n",
        "\n",
        "\n",
        "def load_data():\n",
        "  # Run this cell to download our data into a file called 'cifar_data'\n",
        "  import gdown\n",
        "  # gdown.download('https://drive.google.com/uc?id=1-BjeqccJdLiBA6PnNinmXSQ6w5BluLem','cifar_data','True'); # dogs v road;\n",
        "  !wget -O cifar_data https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n",
        "\n",
        "  # now load the data from our cloud computer\n",
        "  import pickle\n",
        "  data_dict = pickle.load(open( \"cifar_data\", \"rb\" ));\n",
        "  \n",
        "  data   = data_dict['data']\n",
        "  labels = data_dict['labels']\n",
        "  \n",
        "  return data, labels\n",
        "\n",
        "def plot_one_image(data, labels, img_idx):\n",
        "  from google.colab.patches import cv2_imshow\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  my_img   = data[img_idx, :].squeeze().reshape([32,32,3]).copy()\n",
        "  my_label = labels[img_idx]\n",
        "  print('label: %s'%my_label)\n",
        "  plt.imshow(my_img)\n",
        "  plt.show()\n",
        "  \n",
        "def CNNClassifier(num_epochs=2, layers=1, dropout=0.15):\n",
        "  def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Reshape((32, 32, 3)))\n",
        "    \n",
        "    for i in range(layers):\n",
        "      model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "      model.add(Activation('relu'))\n",
        "    \n",
        "    model.add(Conv2D(32, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Conv2D(64, (3, 3)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Dropout(dropout))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(2))\n",
        "    model.add(Activation('softmax'))\n",
        "\n",
        "    # initiate RMSprop optimizer\n",
        "    opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "    # Let's train the model using RMSprop\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "  return KerasClassifier(build_fn=create_model, epochs=num_epochs, batch_size=10, verbose=2)\n",
        "\n",
        "def plot_acc(history, ax = None, xlabel = 'Epoch #'):\n",
        "    history = history.history\n",
        "    history.update({'epoch':list(range(len(history['val_accuracy'])))})\n",
        "    history = pd.DataFrame.from_dict(history)\n",
        "\n",
        "    best_epoch = history.sort_values(by = 'val_accuracy', ascending = False).iloc[0]['epoch']\n",
        "\n",
        "    if not ax:\n",
        "      f, ax = plt.subplots(1,1)\n",
        "    sns.lineplot(x = 'epoch', y = 'val_accuracy', data = history, label = 'Validation', ax = ax)\n",
        "    sns.lineplot(x = 'epoch', y = 'accuracy', data = history, label = 'Training', ax = ax)\n",
        "    ax.axhline(0.5, linestyle = '--',color='red', label = 'Chance')\n",
        "    ax.axvline(x = best_epoch, linestyle = '--', color = 'green', label = 'Best Epoch')  \n",
        "    ax.legend(loc = 1)    \n",
        "    ax.set_ylim([0.4, 1])\n",
        "\n",
        "    ax.set_xlabel(xlabel)\n",
        "    ax.set_ylabel('Accuracy (Fraction)')\n",
        "    \n",
        "    plt.show()\n",
        "    \n",
        "def model_to_string(model):\n",
        "    import re\n",
        "    stringlist = []\n",
        "    model.summary(print_fn=lambda x: stringlist.append(x))\n",
        "    sms = \"\\n\".join(stringlist)\n",
        "    sms = re.sub('_\\d\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d\\d','', sms)\n",
        "    sms = re.sub('_\\d','', sms)  \n",
        "    return sms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wkseZ14ms7vs"
      },
      "source": [
        "In this notebook, we will:\n",
        "\n",
        "- Use a pre-built CNN function to classify roads vs. dogs.\n",
        "- Build neural networks from scratch in Keras.\n",
        "- Experiment with building CNN models from scratch in Keras.\n",
        "- (Advanced, Optional) Build CNN models for distinguishing cats from dogs, and even experiment with implementing a famous architecture!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMWQRlTqt6Yn"
      },
      "source": [
        "**Change Hardware Accelerator to GPU to train faster (Runtime -> Change Runtime Type -> Hardware Accelerator -> GPU)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QxGsnvhnn8R"
      },
      "source": [
        "#Loading in Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btr24O6Hqgo6"
      },
      "source": [
        "Once again, let's load in our dog/road dataset and create our training and test set. **What's the shape of each dataset? Why?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmZbrZoKnthN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04971c4d-afcb-4c61-ac6e-170842ecddbc"
      },
      "source": [
        "# load our data\n",
        "data, labels = load_data()\n",
        "data = data.astype(float)\n",
        "labels = categorical_to_numpy(labels)\n",
        "inputs_train, inputs_test, labels_train, labels_test = model_selection.train_test_split(data, labels, test_size=0.2, random_state=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-25 16:24:09--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%201%20-%205/Session%204%20_%205%20-%20Neural%20Networks%20_%20CNN/dogs_v_roads\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.62.128, 172.253.115.128, 172.253.122.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.62.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3689015 (3.5M) [application/octet-stream]\n",
            "Saving to: ‘cifar_data’\n",
            "\n",
            "\rcifar_data            0%[                    ]       0  --.-KB/s               \rcifar_data          100%[===================>]   3.52M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-06-25 16:24:09 (227 MB/s) - ‘cifar_data’ saved [3689015/3689015]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "37O_VE_D1Bdy"
      },
      "source": [
        "# Models for Vision: Convolutional Neural Networks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqrfI4JiVeFr"
      },
      "source": [
        "###Exercise: Exploring Hyperparameters ✍️\n",
        "\n",
        "As you know, there is a famous type of neural network known as convolutional neural networks (CNNs). These types of neural networks work particularly well on problems to do with computer vision. Let's try one out!\n",
        "\n",
        "To load up a simple CNN on scikit-learn, just run:\n",
        "\n",
        "`cnn = CNNClassifier(num_epochs, layers, dropout)`\n",
        "\n",
        "Work with your instructors to review what each parameter means and how it affects the model! The **dropout** represents how many weights we set to 0 during training time, which can help prevent overfitting.\n",
        "\n",
        "**Try different values of num_epochs, layers, and dropout so that you get the best possible accuracy on the test set using `model.score()`**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bmC3-T4KRJgW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb958fa9-d77f-468e-b48b-9d907341e3a2"
      },
      "source": [
        "cnn = CNNClassifier(5, 2, 0.5)\n",
        "cnn.fit(inputs_train, labels_train)\n",
        "preds = cnn.predict(inputs_test)\n",
        "print (cnn.score(inputs_test, labels_test)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "96/96 - 3s - loss: 8.4612 - accuracy: 0.5677\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 1.1177 - accuracy: 0.7646\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.6393 - accuracy: 0.8167\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.4101 - accuracy: 0.8604\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.3327 - accuracy: 0.8813\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "24/24 - 0s\n",
            "24/24 - 1s - loss: 0.1526 - accuracy: 0.9542\n",
            "95.41666507720947\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSwghlVU4WTy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3619eff-1ec2-4e7f-a709-3b9a3b34a48e"
      },
      "source": [
        "print(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0 1 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 1 1 0 1 0 0 1\n",
            " 0 1 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 1 0 0 0 1 0 0 1 0 0 1 1 1 0 0 1 1 1\n",
            " 0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 1 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0\n",
            " 1 1 0 1 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 0 0 0 0 1 0 0 0 0 1 1 0 0 0 1 1 1\n",
            " 1 1 1 0 1 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 0 1 1 1 0 1 1 0 1 1 0 1 1 1 1 1 0\n",
            " 0 0 1 1 1 1 1 0 0 0 1 1 0 1 1 0 1 1 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1\n",
            " 0 1 1 0 1 0 1 0 0 1 1 1 1 0 1 1 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGWpgsVXP1ut"
      },
      "source": [
        "**How well did your neural network perform?** \n",
        "\n",
        "CNNs typically perform better than fully-connected neural networks on vision problems, but, as before, they aren't always consistent. They are also sensitive to a number of parameters. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-XRh5Y5P_CL"
      },
      "source": [
        "## Training and Validation Curves\n",
        "\n",
        "An important aspect of training neural networks is to prevent overfitting. **How would we recognize overfitting?**\n",
        "\n",
        "In the first line of code below, we first **fit** the model on the training data and pass in some validation (or test) data to evaluate it. We call it the **history** because we want to retain information about the accuracy at each epoch.\n",
        "\n",
        "In the second line we plot the history so that we can compare the training and validation accuracies.  \n",
        "\n",
        "```\n",
        "history = model.fit(inputs_train, labels_train, validation_data=(inputs_test, labels_test))\n",
        "plot_acc(history)\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eaFvE2PQEFe"
      },
      "source": [
        "###Exercise: Plotting a training vs. validation curve for our CNN ✍️\n",
        "\n",
        "**After how many epochs does the model begin to overfit? How does this vary as you vary the number of hidden layers and dropout?** Overfitting occurs when the validation accuracy starts to drop below the training accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsVAasDbjARJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "9cf4264a-bc5a-46d1-ad10-b7c8ea44bbaf"
      },
      "source": [
        "history = cnn.fit(inputs_train, labels_train, validation_data=(inputs_test, labels_test))\n",
        "plot_acc(history)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "96/96 - 10s - loss: 4.0553 - accuracy: 0.6115 - val_loss: 0.2592 - val_accuracy: 0.8792\n",
            "Epoch 2/5\n",
            "96/96 - 0s - loss: 0.6940 - accuracy: 0.8042 - val_loss: 0.2440 - val_accuracy: 0.9000\n",
            "Epoch 3/5\n",
            "96/96 - 0s - loss: 0.4700 - accuracy: 0.8542 - val_loss: 0.1510 - val_accuracy: 0.9500\n",
            "Epoch 4/5\n",
            "96/96 - 0s - loss: 0.3257 - accuracy: 0.8854 - val_loss: 0.1408 - val_accuracy: 0.9542\n",
            "Epoch 5/5\n",
            "96/96 - 0s - loss: 0.2807 - accuracy: 0.9146 - val_loss: 0.2533 - val_accuracy: 0.9125\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76z4NAY6afd7"
      },
      "source": [
        "# Building Neural Networks from Scratch in Keras \n",
        "\n",
        "So far, we've used helper functions which pre-build Keras neural network models. Now, we will build them on our own!\n",
        "\n",
        "Let's build a simple Neural Network that solves a familiar problem: distinguishing between dogs and roads."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdngkAX_aCVu"
      },
      "source": [
        "###Exercise: Building a simple Neural Network using Keras! ✍️\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj-Pt3wGCXRu"
      },
      "source": [
        "\n",
        "We're going to build a larger version of this model: \n",
        "\n",
        "![](http://cs231n.github.io/assets/nn1/neural_net.jpeg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-6WGeedvTCS"
      },
      "source": [
        "This network can be described as: \n",
        "* Input Layer: 3072 (32 pixels x 32 pixels x 3 color channels)\n",
        "* Layer 1 (Hidden): 32 neurons that are activated by `'relu'`\n",
        "* Layer 2 (Output): 2 neurons that are activated by `'softmax'`\n",
        "\n",
        "\n",
        "We also want to compile the model with\n",
        "`loss = 'categorical_crossentropy'`\n",
        "\n",
        "Try filling in the blanks below and walking through each line! **If you want a hint or more details, check out the optional reference below.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dp-g9qotbRPU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d2b80c0-9396-4833-8b33-cdee76040c31"
      },
      "source": [
        "# Fill in the blanks with your group!\n",
        "### YOUR CODE HERE:\n",
        "model_1 = Sequential()\n",
        "model_1.add(Dense(1, input_shape = (3,), activation = 'relu'))\n",
        "model_1.add(Dense(3, activation = 'relu'))\n",
        "model_1.add(Dense(3, activation = 'softmax'))\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "                optimizer = 'adam', \n",
        "                metrics = ['accuracy'])\n",
        "model_1.predict_classes([[1,2,3]])\n",
        "### END CODE"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZS6Yl2poIOFm",
        "outputId": "3ff7f4cc-572a-4c4b-f951-dc3eab509bb5"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_20 (Dense)             (None, 1)                 4         \n",
            "_________________________________________________________________\n",
            "dense_21 (Dense)             (None, 3)                 6         \n",
            "_________________________________________________________________\n",
            "dense_22 (Dense)             (None, 3)                 12        \n",
            "=================================================================\n",
            "Total params: 22\n",
            "Trainable params: 22\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "781M4IyhssuA"
      },
      "source": [
        "####**Optional Reference**\n",
        "\n",
        "Here's some information about each step of the process. **You don't need to read through all this - check it as a reference if needed!**\n",
        "\n",
        "**1. Specify model**\n",
        "\n",
        "```\n",
        "model = Sequential()\n",
        "```\n",
        "In this line of code, we build our network where the information flows from LEFT to RIGHT through the network in ONE DIRECTION as opposed to multiple directions. Neurons on the right never pass informations to neurons on the left of it. \n",
        "\n",
        "\n",
        "**2. Add layers to the network**\n",
        "```\n",
        "model.add(Dense(32, input_dim=3072, activation = 'relu'))\n",
        "```\n",
        "In this code, we add a layer of neurons to our network. \n",
        "\n",
        "This layer consists of 32 neurons. Each neuron is DENSE and connects to all of the previous layer's inputs and all of the subsequent layer's outputs. We specify that there are 3072 inputs here, one for each color channel.\n",
        "\n",
        "We also specify what kind of output the neuron will give. If you want the neuron to output a number between 0 and 1 (like a probability!) you would use 'softmax' or 'sigmoid'. If you want the neuron to output any number, you can use 'linear'! You'll also often see 'relu', which is when a neuron will only output positive numbers. \n",
        "\n",
        "```\n",
        "model.add(Dense(2, activation = 'softmax'))\n",
        "```\n",
        "This code is our output layer. We specify that it has two neurons (one that gives the probability of the image being a dog and one that gives the probability of the image being a cat). We specify a softmax activation because we want our probabilities to be between 0 and 1.\n",
        "\n",
        "**3. Turn the model on by compiling it** \n",
        "\n",
        "After having built the network, we want to train and use it, so we have to 'compile' it to prepare. We have to specify at the very least: a loss (how the model measures the quality of its weights), an optimizer (which adjusts the weights), and a metric (how to evaluate our results). Here are some common choices:\n",
        "```\n",
        "model.compile(loss='mean_squared_error',\n",
        "optimizer = 'adam',\n",
        "metrics = ['mean_squared_error'])\n",
        "  ```\n",
        "\n",
        "Once we've created our network, we can use it very simply! Just like we did with sklearn, we define our input data (inputs_test), the true predictions from that data (labels_train), and the number of epochs (passes through our entire dataset). We train our model with `fit`. \n",
        "\n",
        "```\n",
        "model.fit(inputs_train, labels_train)\n",
        "```\n",
        "\n",
        "To use the model, you can use it to predict something with:\n",
        "```\n",
        "y = model.predict_classes(x)\n",
        "```\n",
        "\n",
        "You can actually use the model before you even train it! It just won't perform very well. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YovNRgfuy0Oq"
      },
      "source": [
        "###(Optional) Exercise: Building a multi-layer Neural Net using Keras ✍️\n",
        "\n",
        "Let's try another, bigger example!\n",
        "\n",
        "* Input Layer: 3072 Dimensions\n",
        "\n",
        "* Layer 1: 32 neurons that are activated by `'relu' `and take in 3 inputs.\n",
        "\n",
        "* Layer 2: 16 neurons that are activated by `'relu'`\n",
        "\n",
        "* Layer 3 (out): 2 neurons that is activated by `'sigmoid'`\n",
        "\n",
        "Compile the model with\n",
        "`loss = 'binary_crossentropy'` "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pm-ylEWqbXrQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCbD6siv-Ip-"
      },
      "source": [
        "##Exercise: Building a CNN using Keras! ✍️\n",
        "\n",
        "Now that we know how to build simple neural networks in Keras, let's build a CNN that will perform well on our data set of car and road images. \n",
        "\n",
        "Below is Keras code for a CNN. It will run as-is on the conscientious cars dataset. However, the performance is suboptimal. Add more layers and change the neural network hyperparameters so that the performance will be better. **Can you get the train and validation accuracy to both be higher than 90%?**\n",
        "\n",
        "The Keras core layer API may be a useful reference: https://keras.io/layers/core/ \n",
        "\n",
        "In particular and in addition to adding more of the existing convolutional layers and activations, consider using the following layers after a convolution + activation:\n",
        "\n",
        "`Dropout(N)`\n",
        "\n",
        "`MaxPooling2D(pool_size=(N, N))`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFVHyPKn-V4N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "19818e17-9cfc-48dc-f858-4769b2672829"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Reshape((32, 32, 3)))\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "###\n",
        "###\n",
        "### TODO: ADD MORE LAYERS HERE!!!!!\n",
        "###\n",
        "###\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "# initiate RMSprop optimizer\n",
        "opt = keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "\n",
        "# Let's train the model using RMSprop\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the CNN and plot accuracy.\n",
        "history = model.fit(inputs_train, labels_train, \\\n",
        "                    validation_data=(inputs_test, labels_test), \\\n",
        "                    epochs=70)\n",
        "plot_acc(history)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/70\n",
            "30/30 [==============================] - 2s 26ms/step - loss: 126.6338 - accuracy: 0.5661 - val_loss: 49.4097 - val_accuracy: 0.5750\n",
            "Epoch 2/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 23.1870 - accuracy: 0.7226 - val_loss: 16.8125 - val_accuracy: 0.7542\n",
            "Epoch 3/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 12.4099 - accuracy: 0.8138 - val_loss: 2.4527 - val_accuracy: 0.9125\n",
            "Epoch 4/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 7.9214 - accuracy: 0.8759 - val_loss: 3.6785 - val_accuracy: 0.9125\n",
            "Epoch 5/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 8.1133 - accuracy: 0.8509 - val_loss: 2.3995 - val_accuracy: 0.9292\n",
            "Epoch 6/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.9754 - accuracy: 0.9226 - val_loss: 2.3726 - val_accuracy: 0.9167\n",
            "Epoch 7/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.7229 - accuracy: 0.9011 - val_loss: 7.0817 - val_accuracy: 0.8000\n",
            "Epoch 8/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 9.8867 - accuracy: 0.8405 - val_loss: 2.6868 - val_accuracy: 0.9292\n",
            "Epoch 9/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.1123 - accuracy: 0.9149 - val_loss: 1.4980 - val_accuracy: 0.9375\n",
            "Epoch 10/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 2.6102 - accuracy: 0.9292 - val_loss: 0.8619 - val_accuracy: 0.9542\n",
            "Epoch 11/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 2.1814 - accuracy: 0.9164 - val_loss: 1.0966 - val_accuracy: 0.9500\n",
            "Epoch 12/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 1.5250 - accuracy: 0.9341 - val_loss: 1.1809 - val_accuracy: 0.9542\n",
            "Epoch 13/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 2.4727 - accuracy: 0.9063 - val_loss: 1.0563 - val_accuracy: 0.9458\n",
            "Epoch 14/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 2.1330 - accuracy: 0.9444 - val_loss: 0.9535 - val_accuracy: 0.9583\n",
            "Epoch 15/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.0433 - accuracy: 0.9634 - val_loss: 0.9057 - val_accuracy: 0.9458\n",
            "Epoch 16/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.8640 - accuracy: 0.9618 - val_loss: 1.0631 - val_accuracy: 0.9417\n",
            "Epoch 17/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.3221 - accuracy: 0.9842 - val_loss: 0.8223 - val_accuracy: 0.9500\n",
            "Epoch 18/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.4158 - accuracy: 0.9726 - val_loss: 0.8962 - val_accuracy: 0.9583\n",
            "Epoch 19/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.3283 - accuracy: 0.9751 - val_loss: 1.2330 - val_accuracy: 0.9333\n",
            "Epoch 20/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9898 - val_loss: 0.9286 - val_accuracy: 0.9375\n",
            "Epoch 21/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.4076 - accuracy: 0.9795 - val_loss: 1.1197 - val_accuracy: 0.9500\n",
            "Epoch 22/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1394 - accuracy: 0.9838 - val_loss: 0.8999 - val_accuracy: 0.9500\n",
            "Epoch 23/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.4005 - accuracy: 0.9820 - val_loss: 1.0470 - val_accuracy: 0.9458\n",
            "Epoch 24/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.2565 - accuracy: 0.9824 - val_loss: 0.8403 - val_accuracy: 0.9458\n",
            "Epoch 25/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0275 - accuracy: 0.9958 - val_loss: 0.7725 - val_accuracy: 0.9542\n",
            "Epoch 26/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1195 - accuracy: 0.9970 - val_loss: 1.1141 - val_accuracy: 0.9542\n",
            "Epoch 27/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1742 - accuracy: 0.9871 - val_loss: 0.8603 - val_accuracy: 0.9542\n",
            "Epoch 28/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.2252 - accuracy: 0.9856 - val_loss: 0.8639 - val_accuracy: 0.9417\n",
            "Epoch 29/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 8.2971e-06 - accuracy: 1.0000 - val_loss: 0.8748 - val_accuracy: 0.9417\n",
            "Epoch 30/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.9352 - accuracy: 0.9634 - val_loss: 1.2144 - val_accuracy: 0.9500\n",
            "Epoch 31/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.1980 - accuracy: 0.9813 - val_loss: 1.2007 - val_accuracy: 0.9500\n",
            "Epoch 32/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.1392 - accuracy: 0.9872 - val_loss: 1.2292 - val_accuracy: 0.9458\n",
            "Epoch 33/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0517 - accuracy: 0.9922 - val_loss: 1.1625 - val_accuracy: 0.9458\n",
            "Epoch 34/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0333 - accuracy: 0.9969 - val_loss: 1.0826 - val_accuracy: 0.9417\n",
            "Epoch 35/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.1788 - accuracy: 0.9802 - val_loss: 1.7716 - val_accuracy: 0.9000\n",
            "Epoch 36/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.1585 - accuracy: 0.9793 - val_loss: 1.1677 - val_accuracy: 0.9500\n",
            "Epoch 37/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 1.6574e-05 - accuracy: 1.0000 - val_loss: 1.2538 - val_accuracy: 0.9542\n",
            "Epoch 38/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 2.1112e-06 - accuracy: 1.0000 - val_loss: 1.1896 - val_accuracy: 0.9542\n",
            "Epoch 39/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 4.4161e-08 - accuracy: 1.0000 - val_loss: 1.1809 - val_accuracy: 0.9542\n",
            "Epoch 40/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 1.0713e-07 - accuracy: 1.0000 - val_loss: 1.1773 - val_accuracy: 0.9542\n",
            "Epoch 41/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 2.1051e-07 - accuracy: 1.0000 - val_loss: 8.6940 - val_accuracy: 0.7292\n",
            "Epoch 42/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.6206 - accuracy: 0.9736 - val_loss: 1.2684 - val_accuracy: 0.9375\n",
            "Epoch 43/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 3.5743e-08 - accuracy: 1.0000 - val_loss: 1.2872 - val_accuracy: 0.9375\n",
            "Epoch 44/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 6.4046e-08 - accuracy: 1.0000 - val_loss: 1.2875 - val_accuracy: 0.9375\n",
            "Epoch 45/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 6.3110e-09 - accuracy: 1.0000 - val_loss: 1.3005 - val_accuracy: 0.9375\n",
            "Epoch 46/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 1.8423e-08 - accuracy: 1.0000 - val_loss: 1.2979 - val_accuracy: 0.9375\n",
            "Epoch 47/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.6706e-08 - accuracy: 1.0000 - val_loss: 1.2960 - val_accuracy: 0.9417\n",
            "Epoch 48/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 1.5968e-09 - accuracy: 1.0000 - val_loss: 1.2977 - val_accuracy: 0.9417\n",
            "Epoch 49/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 1.5787e-09 - accuracy: 1.0000 - val_loss: 1.3017 - val_accuracy: 0.9375\n",
            "Epoch 50/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 2.1490e-09 - accuracy: 1.0000 - val_loss: 1.2929 - val_accuracy: 0.9375\n",
            "Epoch 51/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 1.2155e-11 - accuracy: 1.0000 - val_loss: 1.3122 - val_accuracy: 0.9458\n",
            "Epoch 52/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 9.1063e-10 - accuracy: 1.0000 - val_loss: 1.2662 - val_accuracy: 0.9417\n",
            "Epoch 53/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 3.0890e-10 - accuracy: 1.0000 - val_loss: 1.3139 - val_accuracy: 0.9500\n",
            "Epoch 54/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 5.0729e-10 - accuracy: 1.0000 - val_loss: 1.2596 - val_accuracy: 0.9417\n",
            "Epoch 55/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 6.2856e-10 - accuracy: 1.0000 - val_loss: 1.2589 - val_accuracy: 0.9417\n",
            "Epoch 56/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 2.6377e-10 - accuracy: 1.0000 - val_loss: 1.2934 - val_accuracy: 0.9417\n",
            "Epoch 57/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.3025 - val_accuracy: 0.9417\n",
            "Epoch 58/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2878 - val_accuracy: 0.9417\n",
            "Epoch 59/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2864 - val_accuracy: 0.9417\n",
            "Epoch 60/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2950 - val_accuracy: 0.9417\n",
            "Epoch 61/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2912 - val_accuracy: 0.9417\n",
            "Epoch 62/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2846 - val_accuracy: 0.9417\n",
            "Epoch 63/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2877 - val_accuracy: 0.9417\n",
            "Epoch 64/70\n",
            "30/30 [==============================] - 0s 7ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2882 - val_accuracy: 0.9417\n",
            "Epoch 65/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2817 - val_accuracy: 0.9417\n",
            "Epoch 66/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2832 - val_accuracy: 0.9417\n",
            "Epoch 67/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2843 - val_accuracy: 0.9417\n",
            "Epoch 68/70\n",
            "30/30 [==============================] - 0s 5ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2795 - val_accuracy: 0.9417\n",
            "Epoch 69/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2820 - val_accuracy: 0.9417\n",
            "Epoch 70/70\n",
            "30/30 [==============================] - 0s 6ms/step - loss: 0.0000e+00 - accuracy: 1.0000 - val_loss: 1.2807 - val_accuracy: 0.9417\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JFLu0CdXM6K"
      },
      "source": [
        "**What interesting observations** do you make from the graph? How many epochs should you train for?\n",
        "\n",
        "We can also print out the structure of our model. What do the parts of the summary mean?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RGwXs3C8YZl-"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YXINPAJvRr9W"
      },
      "source": [
        "#Advanced: Cats vs. Dogs with CNN\n",
        "\n",
        "So far, we've trained a CNN to distinguish between small images of cats and small images of dogs. It's more challenging and time-consuming to train CNNs for bigger images or harder tasks, like distinguishing dogs from cats (which look a lot more like dogs than roads do!)\n",
        "\n",
        "In this exercise, you'll adapt your previous model to classify large images of dogs vs. cats, and then try implementing a famous CNN architecture. Along the way, you'll deal with some of the debugging that machine learning engineers often have to handle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gU39z3jNMAt"
      },
      "source": [
        "#@title Run this to load cat and dog data. { display-mode: \"form\" }\n",
        "\n",
        "#Code here from https://colab.research.google.com/github/google/eng-edu/blob/master/ml/pc/exercises/image_classification_part1.ipynb#scrollTo=4PIP1rkmeAYS\n",
        "\n",
        "import tensorflow as tf\n",
        "import os \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from google.colab.patches import cv2_imshow\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  road_model = model\n",
        "  road_saved = True\n",
        "except NameError:\n",
        "  road_saved = False\n",
        "\n",
        "IMG_SHAPE  = 150  # Our training data consists of images with width of 150 pixels and height of 150 pixels\n",
        "_URL = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n",
        "zip_dir = tf.keras.utils.get_file('cats_and_dogs_filterted.zip', origin=_URL, extract=True)\n",
        "base_dir = os.path.join(os.path.dirname(zip_dir), 'cats_and_dogs_filtered')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_cats_dir = os.path.join(train_dir, 'cats')  # directory with our training cat pictures\n",
        "train_dogs_dir = os.path.join(train_dir, 'dogs')  # directory with our training dog pictures\n",
        "validation_cats_dir = os.path.join(validation_dir, 'cats')  # directory with our validation cat pictures\n",
        "validation_dogs_dir = os.path.join(validation_dir, 'dogs')  # directory with our validation dog pictures\n",
        "train_image_generator      = ImageDataGenerator()  # Generator for our training data\n",
        "validation_image_generator = ImageDataGenerator()  # Generator for our validation data\n",
        "train_data = train_image_generator.flow_from_directory(batch_size=2000,\n",
        "                                                           directory=train_dir,\n",
        "                                                           shuffle=True,\n",
        "                                                           target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "                                                           class_mode='binary').next()\n",
        "val_data = validation_image_generator.flow_from_directory(batch_size=1000,\n",
        "                                                              directory=validation_dir,\n",
        "                                                              shuffle=False,\n",
        "                                                              target_size=(IMG_SHAPE,IMG_SHAPE), #(150,150)\n",
        "\n",
        "                                                              class_mode='binary').next()\n",
        "cd_train_inputs, cd_train_labels = train_data\n",
        "cd_test_inputs, cd_test_labels = val_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y5etOJwScaG"
      },
      "source": [
        "**Run the code below to see the dimensions of our training and validation data. What does each number mean? What is different than our previous dataset?** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjdedJ0VNvWg"
      },
      "source": [
        "print (cd_train_inputs.shape) \n",
        "print (cd_train_labels.shape) \n",
        "print (cd_test_inputs.shape) \n",
        "print (cd_test_labels.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIAkgOqWTAL7"
      },
      "source": [
        "**Run this code to see a random image from our training data (different each time).**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HooiJ-RrQPcA"
      },
      "source": [
        "index = np.random.randint(len(cd_train_inputs))\n",
        "plt.imshow(cd_train_inputs[index]/255)\n",
        "plt.show()\n",
        "print(\"Label:\",cd_train_labels[index])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOwP9kX9UshH"
      },
      "source": [
        "**By adapting code from the previous exercise, build, train, and test a CNN to classify cats vs. dogs.**\n",
        "**Hints:**\n",
        "*   Use print(model.summary()) for a useful visualization of your model's architecture. Compare the summary of your cat/road and cat/dog classifiers.\n",
        "*  Substitute the names of the new datasets.\n",
        "*  Get a \"first try\" working by making small adjustments to a previous model before trying to optimize the accuracy. You can temporarily comment out layers as you figure things out.\n",
        "*  The outputs have different shapes betweeen the two datasets. What do you need to change? (You will get an ValueError that suggests how to transform the output to a one-hot encoding.) \n",
        "*  If you run out of memory, restart the notebook and/or use your knowledge of convolution arithmetic to reduce the size of an intermediate output (see [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D)).\n",
        "* Dropout layers help reduce overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeuqlzigZZ8I"
      },
      "source": [
        "model = Sequential()\n",
        "#TODO: Your code here to build, train, and test a cats vs. dogs CNN!\n",
        "#If you run into errors, see the hints above for help debugging! \n",
        "#\n",
        "#\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6sFSGEqjPwe"
      },
      "source": [
        "#Advanced Challenge: Implementing a Famous Architecture for Cats vs. Dogs\n",
        "\n",
        "Having trouble designing an effective architecture? Try implementing a version of AlexNet, one of the most famous CNNs for image convolution ever. You can find this image and other useful information on this network [here](https://towardsdatascience.com/the-w3h-of-alexnet-vggnet-resnet-and-inception-7baaaecccc96).\n",
        "\n",
        "![](https://lh4.googleusercontent.com/gFAxn9Z-Y1lgkNy2GfsqjXy1DvSuYF8rvP3CslRvmuoP5SUaJMrEOr24YShU_LwalLpYNJFwpJgcDh9whk9XrMOGQ1ADQ9FY_0saicCVH0jsNPDKOYBcTG4YhbqpbPolW4hZSdUsDQ)\n",
        "\n",
        "How do we read this diagram?\n",
        "\n",
        "On the left side, we start with images of dimension 227x227x3 (RGB). We apply a filter composed of 96 kernels of size 11x11, with stride size 4. We end up with data of dimension 55x55x96. We pass through multiple layers of convolution and max pooling as shown, before ending with three dense (fully connected) layers.\n",
        "\n",
        "Not shown: each layer uses ReLU activation, and we include dropout before the first two dense layers. Make sure to include those!\n",
        "\n",
        "You'll want to adjust some of these dimensions, for a few reasons: we're starting with 150x150 rather than 227x227 images, ending with 2 labels rather than 1000, and have limited data and memory. Use your knowledge of convolution arithmetic (see CNN slides) and the [Keras documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D) to change the stride, kernel, and/or padding.\n",
        "\n",
        "Use model.summary() to understand the dimensions of your data at each step. To speed things up as you're building, you can set the number of epochs to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FHg8YTGtQ2t"
      },
      "source": [
        "model = Sequential()\n",
        "#TODO: Your code to run, train, and test AlexNet here:\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PlF308hDjwyC"
      },
      "source": [
        "You might find that even AlexNet isn't working that well for you!\n",
        "\n",
        "This is because having a good architecture is only half the battle: AlexNet is a complex model designed to learn from millions of images. We're using a small dataset of only 2000 training images, so it's not surprising that our results aren't great. Our model is overfitting: essentially memorizing the few training images, rather than really learning the difference between a cat and a dog. (The advantage is that our model trains quickly.)\n",
        "\n",
        "To get really good performance, we need more data. If we can't find more, we could use *data augmentation*: inventing new training data by transforming our existing images. You can read more about it at https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVzEpI_xWpE5"
      },
      "source": [
        "![](https://images.pexels.com/photos/316/black-and-white-animal-dog-pet.jpg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940)"
      ]
    }
  ]
}